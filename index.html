<!DOCTYPE html>
<html lang="en">
<head>
	<meta name="generator" content="Hugo 0.42.1" />
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	
	<title> Seong Woo Han</title>
	
	<meta name="description" content="">
	<meta name="image" content="">
	
	<meta itemprop="name" content="">
	<meta itemprop="description" content="">
	<meta itemprop="image" content="">
	
	<meta name="og:title" content="">
	<meta name="og:description" content="">
	
	<meta name="og:url" content="https://seongwoohan.github.io/">
	<meta name="og:site_name" content="">
	<meta name="og:type" content="article">
	<link rel="shortcut icon" href="https://seongwoohan.github.io//favicon.ico" type="image/x-icon">
	
	<meta name="article:tag" content="">
	<link rel="stylesheet" type="text/css" href="https://irenechen.net/css/style.css">

	
	
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-72495497-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	<script defer src="/static/fontawesome/fontawesome-all.js"></script>
	

	
	
	
</head>

<body>

<header>
	
	<div style="text-align: bottom">
		<a href="https://seongwoohan.github.io//" style="float: left;" class="namelogo">Seong Woo Han</a>
	
	
	</div>
</header>





<div class="content">
  <h1></h1>
  <aside></aside>
  <p>

<p><img class="profile-picture" src="images/seongwoohan.jpg"></p>

<p>I am a senior math student at New York University. I am <br /> broadly interested in mathematical modeling, machine learning, and their applications in healthcare and genomics. Also, I am interested in methods for causal inference with a focus on algorithmic fariness.</p>

<p>I am fortunate to work on mathemtacal modeling research in congenital heart diesease with <a href="https://www.math.nyu.edu/faculty/peskin//">Prof. Charles Peskin</a>.</p>

<p>Email : swh324 [at] nyu [dot] edu</p>

<p><br></p>

<h2 id="Research">Research</h2>

<script>
function absCHF() {
    var x = document.getElementById("abs-fairness");
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>

<h4 id="Project">Project</h4>

<p><strong>ClinicalKnockoffs: Identification of significant features for Hospital Readmission</strong>
<br>
Abed Qaddoumi, <b>Seong Woo Han</br>
<br>
<em>Technical Report 2019</em>
<br>
[<a href="files/ClinicalKnockoffs_Han, Qaddoumi.pdf">pdf</a>]</p>

<p><strong>Why Is My Classifier Discriminatory?</strong>
<br>
Irene Y. Chen, Fredrik D. Johansson, David Sontag.
<br>
<em>NeurIPS 2018</em>, <b><font color="#B03A2E">Spotlight Presentation (top 4% of submitted papers)</font></b>.
<br>
[<a id="abs-fairness-button" onclick="absCHF()">abstract</a>, <a href="https://arxiv.org/abs/1805.12002">pdf</a>, <a href="/assets/neurips18_slides.pdf">slides</a>, <a href="/assets/neurips18_poster.pdf">poster</a>]</p>

<div id="abs-fairness" style="display:none;">
<blockquote>Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.</blockquote>
</div>

<p><strong>Sources of Unfairness in Intensive Care Unit Mortality Scores.</strong> <br>Irene Y. Chen, Fredrik D. Johansson, David Sontag. <br> <em>Women in Machine Learning Workshop at NeurIPS 2017.</em></p>

<h4 id="journals">Journals</h4>

<p><strong>Treating health disparities with artificial intelligence</strong>
<br>
Irene Y. Chen, Shalmali Joshi, Marzyeh Ghassemi
<br>
<em>Nature Medicine</em>, January 2020.
<br>
[<a href="https://www.nature.com/articles/s41591-019-0649-2">pdf</a>]</p>


</div>

<footer>
	<p><a href="https://github.com/poole/lanyon">Website template credits.</a></p>
</footer>
</body>
</html>
