<!DOCTYPE html>
<html lang="en">
<head>
	<meta name="generator" content="Hugo 0.42.1" />
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	
	<title> Seong Woo Han</title>
	
	<meta name="description" content="">
	<meta name="image" content="">
	
	<meta itemprop="name" content="">
	<meta itemprop="description" content="">
	<meta itemprop="image" content="">
	
	<meta name="og:title" content="">
	<meta name="og:description" content="">
	
	<meta name="og:url" content="https://seongwoohan.github.io/">
	<meta name="og:site_name" content="">
	<meta name="og:type" content="article">
	<link rel="shortcut icon" href="https://seongwoohan.github.io//favicon.ico" type="image/x-icon">
	
	<meta name="article:tag" content="">
	<link rel="stylesheet" type="text/css" href="https://irenechen.net/css/style.css">

	
	
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-72495497-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	<script defer src="/static/fontawesome/fontawesome-all.js"></script>
	

	
	
	
</head>

<body>

<header>
	
	<div style="text-align: bottom">
		<a href="https://seongwoohan.github.io//" style="float: left;" class="namelogo">Seong Woo Han</a>
	
	
	</div>
</header>





<div class="content">
  <h1></h1>
  <aside></aside>
  <p>

<p><img class="profile-picture" src="images/seongwoohan.jpg"></p>

<p>I&rsquo;m a Senior Math student at the Courant Institute of Mathematical Sciences, New York University. I am broadly interested in mathematical modeling and machine learning and their applications in healthcare and genomics. I 'm also interested in methods for causal inference with a focus on robust algorithmic fariness.</p>

<p>I am fortunate to work with <a href="https://www.math.nyu.edu/faculty/peskin//">Prof. Charles Peskin</a>.</p> and <a href="https://cpuelz.github.io//">Dr. Charles Puelz</a>.</p> in mathemtacal modeling congential heart diesease.</p>

<p>Email : swh324 [at] nyu [dot] edu</p>

<p><br></p>

<h2 id="Research">Research</h2>

<script>
function absCHF() {
    var x = document.getElementById("abs-fairness");
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>

<h4 id="conferences">Conferences</h4>

<p><strong>Robustly Extracting Medical Knowledge from EHRs: A Case Study of Learning a Health Knowledge Graph.</strong>
<br>
Irene Y. Chen, Monica Agrawal, Steven Horng, David Sontag.
<br>
<em>PSB 2020</em>, <b><font color="#B03A2E">Oral Presentation</font></b>.
<br>
[<a href="https://arxiv.org/abs/1910.01116">pdf</a>]</p>

<p><strong>Why Is My Classifier Discriminatory?</strong>
<br>
Irene Y. Chen, Fredrik D. Johansson, David Sontag.
<br>
<em>NeurIPS 2018</em>, <b><font color="#B03A2E">Spotlight Presentation (top 4% of submitted papers)</font></b>.
<br>
[<a id="abs-fairness-button" onclick="absCHF()">abstract</a>, <a href="https://arxiv.org/abs/1805.12002">pdf</a>, <a href="/assets/neurips18_slides.pdf">slides</a>, <a href="/assets/neurips18_poster.pdf">poster</a>]</p>

<div id="abs-fairness" style="display:none;">
<blockquote>Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.</blockquote>
</div>

<p><strong>Sources of Unfairness in Intensive Care Unit Mortality Scores.</strong> <br>Irene Y. Chen, Fredrik D. Johansson, David Sontag. <br> <em>Women in Machine Learning Workshop at NeurIPS 2017.</em></p>

<h4 id="journals">Journals</h4>

<p><strong>Treating health disparities with artificial intelligence</strong>
<br>
Irene Y. Chen, Shalmali Joshi, Marzyeh Ghassemi
<br>
<em>Nature Medicine</em>, January 2020.
<br>
[<a href="https://www.nature.com/articles/s41591-019-0649-2">pdf</a>]</p>

<p><strong>Trends and Focus of Machine Learning Applications for Health Research</strong>
<br>
Brett Beaulieu-Jones, Samuel G. Finlayson, Corey Chivers, Irene Y. Chen, Matthew McDermott, Jaz Kandola, Adrian V. Dalca, Andrew Beam, Madalina Fiterau, Tristan Naumann
<br>
<em>JAMA Network Open</em>, October 2019.
<br>
[<a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2753523">pdf</a>]</p>

<p><strong>Turning the crank for machine learning: ease, at what expense?</strong>
<br>
Tom J. Pollard, Irene Y. Chen, Jenna Wiens, Steven Horng, Danny Wong, Marzyeh Ghassemi, Heather Mattie, Emily Lindmeer, Trishan Panch.
<br>
<em>Lancet Digital Health</em>, September 2019.
<br>
[<a href="https://www.thelancet.com/journals/landig/article/PIIS2589-7500(19)30112-8/fulltext">pdf</a>]</p>

<p><strong>Practical guidance on artificial intelligence for health-care data.</strong>
<br>
Marzyeh Ghassemi, Tristan Naumann, Peter Schulam, Andrew L. Beam, Irene Y. Chen, Rajesh Ranganath.
<br>
<em>Lancet Digital Health</em>, August 2019.
<br>
[<a href="https://www.thelancet.com/journals/landig/article/PIIS2589-7500(19)30084-6/fulltext">pdf</a>]</p>

<p><strong>Can AI Help Reduce Disparities in General Medical and Mental Health Care?</strong>
<br>
Irene Y. Chen, Peter Szolovits, Marzyeh Ghassemi.
<br>
<em>AMA Journal of Ethics</em>, February 2019.
<br>
[<a href="https://journalofethics.ama-assn.org/article/can-ai-help-reduce-disparities-general-medical-and-mental-health-care/2019-02">pdf</a>]</p>

<h4 id="other">Other</h4>

<p><strong>We should treat algorithms like prescription drugs.</strong>
<br>
Andy Coravos, Irene Chen, Ankit Gordhandas, Ariel Dora Stern.
<br>
<em>Quartz</em>, February 14, 2019.
<br>
[<a href="https://qz.com/1540594/treating-algorithms-like-prescription-drugs-could-reduce-ai-bias/">link</a>]</p>



<h2 id="hobbies">Hobbies</h2>

<p>In my free time, I enjoy <a href="https://twitter.com/irenetrampoline/status/986059482022273024">long distance running</a>, <a href="./reading-list">reading books</a>, and <a href="https://mitaiethics.github.io">discussing AI ethics</a>.</p>
</p>
</div>

<footer>
	<p>&copy; 2020 All rights reserved.</p>
</footer>
</body>
</html>
